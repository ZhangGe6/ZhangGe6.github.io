<feed xmlns="http://www.w3.org/2005/Atom"> <id>https://zhangge6.github.io/</id><title>ZhangGe's Blog</title><subtitle>A minimal, responsive, and powerful Jekyll theme for presenting professional writing.</subtitle> <updated>2025-09-16T22:50:30+08:00</updated> <author> <name>ZhangGe</name> <uri>https://zhangge6.github.io/</uri> </author><link rel="self" type="application/atom+xml" href="https://zhangge6.github.io/feed.xml"/><link rel="alternate" type="text/html" hreflang="zh" href="https://zhangge6.github.io/"/> <generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator> <rights> © 2025 ZhangGe </rights> <icon>/assets/img/favicons/favicon.ico</icon> <logo>/assets/img/favicons/favicon-96x96.png</logo> <entry><title>GPU通信元语</title><link href="https://zhangge6.github.io/posts/GPU%E9%80%9A%E4%BF%A1%E5%85%83%E8%AF%AD/" rel="alternate" type="text/html" title="GPU通信元语" /><published>2025-07-13T15:46:00+08:00</published> <updated>2025-09-16T20:58:21+08:00</updated> <id>https://zhangge6.github.io/posts/GPU%E9%80%9A%E4%BF%A1%E5%85%83%E8%AF%AD/</id> <content src="https://zhangge6.github.io/posts/GPU%E9%80%9A%E4%BF%A1%E5%85%83%E8%AF%AD/" /> <author> <name>Zhang Ge</name> </author> <category term="专业积累" /> <category term="LLM推理" /> <summary> 总览 随着模型越来越大，单卡的算力和显存已经无法满足需求，多卡并行顺势而生。通信在多卡并行中扮演着重要角色，对性能也有影响。本文总结一些常见的通信元语，更多关注于推理（而不是训练）。 多卡并行中常见的通信元语 通信元语 Broadcast Scatter Reduce AllReduce 通信量： 数学性质(参考)：AllReduce = reduceScatter + allGather 典型使用场景：TP后的加和规约。 Gather AllGather ReduceScatter AlltoAll https://images.nvidia.com/events/sc15/pdfs/NCCL-Woolley.pdf https://www.zhihu.com/search?type=content&amp;amp;q=moe%20alltoal... </summary> </entry> <entry><title>DistServe阅读笔记</title><link href="https://zhangge6.github.io/posts/DistServe%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" rel="alternate" type="text/html" title="DistServe阅读笔记" /><published>2025-07-13T15:46:00+08:00</published> <updated>2025-07-13T15:46:00+08:00</updated> <id>https://zhangge6.github.io/posts/DistServe%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</id> <content src="https://zhangge6.github.io/posts/DistServe%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" /> <author> <name>Zhang Ge</name> </author> <category term="专业积累" /> <category term="编程积累" /> <summary> 论文原文：https://arxiv.org/abs/2401.09670 Why PD Disag make sense independent tuing (KEY) How to get PD Disag profit Limitations/not suggested situations 优化throughut的场景：PD分离目标在于时延。换句话说，如果TTFT和TPOT优化得更好，那么在给定的TTFT和TPOT约束下，就可以达到更高的request rate。如果目标是最大化throughput（比如offline inference），那么不分离的chunked prefill更适合，因为可以把GPU打得更满。 GPU资源有限的场景：PD分离后的设计需要精心设计。GPU数量少，PD分离的设计空间（比如PD配比，并行方式）就会受限。（很）有可能分离后性能... </summary> </entry> <entry><title>gdb学习</title><link href="https://zhangge6.github.io/posts/gdb%E5%AD%A6%E4%B9%A0/" rel="alternate" type="text/html" title="gdb学习" /><published>2023-07-09T15:35:00+08:00</published> <updated>2023-11-20T23:38:44+08:00</updated> <id>https://zhangge6.github.io/posts/gdb%E5%AD%A6%E4%B9%A0/</id> <content src="https://zhangge6.github.io/posts/gdb%E5%AD%A6%E4%B9%A0/" /> <author> <name>Zhang Ge</name> </author> <category term="实践" /> <category term="硬技能" /> <summary> 初步 怎么运行gdb？ 写一个有bug的程序 // crash.cpp #include &amp;lt;iostream&amp;gt; using namespace std; int divint(int, int); int main() { x = 3; y = 0; cout &amp;lt;&amp;lt; divint(x, y); return 0; } int divint(int a, int b) { return a / b; } 使用g++编译程序，运行出错 g++ crash.cpp -o crash ./crash # Floating point exception (core dumped) 增加-g选项，编译debug版本 g++ -g crash.cpp -o crash_gdb 启动gdb ... </summary> </entry> <entry><title>【WIP】推理图优化方法小结</title><link href="https://zhangge6.github.io/posts/%E6%8E%A8%E7%90%86%E5%9B%BE%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%B0%8F%E7%BB%93/" rel="alternate" type="text/html" title="【WIP】推理图优化方法小结" /><published>2023-02-13T20:31:00+08:00</published> <updated>2023-11-20T23:38:44+08:00</updated> <id>https://zhangge6.github.io/posts/%E6%8E%A8%E7%90%86%E5%9B%BE%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%B0%8F%E7%BB%93/</id> <content src="https://zhangge6.github.io/posts/%E6%8E%A8%E7%90%86%E5%9B%BE%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%B0%8F%E7%BB%93/" /> <author> <name>Zhang Ge</name> </author> <category term="实践" /> <summary> 在神经网络推理过程中，图优化可以达到降低运算量、减少算子invoke数目与降低缓存开销等效果，提升推理效率。本文对常见的推理图优化方法进行小结，并不断增补中。 符号定义 卷积、全连接层运算 设卷积或全连接层$Layer(W, b)$的权重和偏置为\(W\)和\(b\)，输入和输出分别为\(X\)和\(X^{\prime}\)，有 \(X^{\prime} = X \otimes W + b\) 其中$\otimes$代表卷积或矩阵乘法操作。$X \in \mathbf{R}^{c\times h \times w}, \ \ X^{\prime} \in \mathbf{R}^{c^{\prime} \times h^{\prime} \times w^{\prime}}, \ \ b \in \mathbf{R}^{c^{\prime}}.$ 当$Layer$为卷积层... </summary> </entry> <entry><title>Flask项目部署记录（uwsgi）</title><link href="https://zhangge6.github.io/posts/Flask%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95-uwsgi/" rel="alternate" type="text/html" title="Flask项目部署记录（uwsgi）" /><published>2022-11-14T21:17:00+08:00</published> <updated>2023-11-20T23:38:44+08:00</updated> <id>https://zhangge6.github.io/posts/Flask%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95-uwsgi/</id> <content src="https://zhangge6.github.io/posts/Flask%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95-uwsgi/" /> <author> <name>Zhang Ge</name> </author> <category term="实践" /> <category term="硬技能" /> <summary> Flask是一个使用Python编写的轻量级Web应用框架。基于它可以很方便地搭建起一个Web应用，但其内建服务器不适用于生产环境。所以当在本地完成了一个Flask应用，为了更高效、安全、稳定地把它展示给全世界，是时候部署它了！ 本页记录我把一个Flask应用部署到腾讯云服务器上的操作过程，用到了uwsgi。 再进一步地，为了支持高性能、高并发，还可以用到nginx。但这一步我暂时还没弄清楚，等后续有机会实操并成功后再做记录。 服务器准备 在腾讯云租用一个服务器，会分配一个公网ip地址。 （首次连接前，需要）配置服务器的SSH用户名和密码 我租用的是一台“轻量级服务器”，它的SSH配置指南见这里 :star:关于端口 创建实例时默认已开通22端... </summary> </entry> </feed>
