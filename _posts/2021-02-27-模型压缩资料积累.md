---
title: 模型压缩资料积累
author: Zhang Ge
date: 2021-02-27 22:41:00 +0800
categories: [专业积累, 模型压缩]
tags: []
---

深度学习的模型压缩可能就是自己硕士阶段的研究课题啦，这篇博客记录在学习过程中遇到的比较好的资料，作为积累和备忘。

# github awesome collections

- [htqin/awesome-model-quantization](https://github.com/htqin/awesome-model-quantization)![GitHub stars](https://img.shields.io/github/stars/htqin/awesome-model-quantization.svg?style=flat&label=Star)
  - A list of papers, docs, codes about model quantization. This repo is aimed to provide the info for model quantization research.
- [csyhhu/Awesome-Deep-Neural-Network-Compression](https://github.com/csyhhu/Awesome-Deep-Neural-Network-Compression)![GitHub stars](https://img.shields.io/github/stars/csyhhu/Awesome-Deep-Neural-Network-Compression.svg?style=flat&label=Star)
	- Summary, Code for Deep Neural Network Quantization
- [chester256/Model-Compression-Papers](https://github.com/chester256/Model-Compression-Papers)![GitHub stars](https://img.shields.io/github/stars/chester256/Model-Compression-Papers.svg?style=flat&label=Star)
	- Papers for deep neural network compression and acceleration
- [juliagusak/model-compression-and-acceleration-progress](https://github.com/juliagusak/model-compression-and-acceleration-progress)![GitHub stars](https://img.shields.io/github/stars/juliagusak/model-compression-and-acceleration-progress.svg?style=flat&label=Star)
- [he-y/Awesome-Pruning](https://github.com/he-y/Awesome-Pruning)
  - A curated list of neural network pruning resources.
- [FLHonker/Awesome-Knowledge-Distillation](https://github.com/FLHonker/Awesome-Knowledge-Distillation)![GitHub stars](https://img.shields.io/github/stars/FLHonker/Awesome-Knowledge-Distillation.svg?style=flat&label=Star)
  - Awesome Knowledge-Distillation. 分类整理的知识蒸馏paper(2014-2021)。

# github project repo

- [IntelLabs/distiller](https://github.com/IntelLabs/distiller)![GitHub stars](https://img.shields.io/github/stars/IntelLabs/distiller.svg?style=flat&label=Star)
  - Neural Network Distiller by Intel AI Lab: a Python package for neural network compression research.

- [j-marple-dev/model_compression](https://github.com/j-marple-dev/model_compression)![GitHub stars](https://img.shields.io/github/stars/j-marple-dev/model_compression.svg?style=flat&label=Star)


- [lucamocerino/Binary-Neural-Networks-PyTorch-1.0](https://github.com/lucamocerino/Binary-Neural-Networks-PyTorch-1.0)![GitHub stars](https://img.shields.io/github/stars/lucamocerino/Binary-Neural-Networks-PyTorch-1.0.svg?style=flat&label=Star)
  - BNNs (XNOR, BNN and DoReFa) implementation for PyTorch 1.0+
- [jiecaoyu/XNOR-Net-PyTorch](https://github.com/jiecaoyu/XNOR-Net-PyTorch)![GitHub stars](https://img.shields.io/github/stars/jiecaoyu/XNOR-Net-PyTorch.svg?style=flat&label=Star)
- [666DZY666/micronet](https://github.com/666DZY666/micronet)![GitHub stars](https://img.shields.io/github/stars/666DZY666/micronet.svg?style=flat&label=Star)

  - 可供模型压缩加速入门参考
- [JDAI-CV/dabnn](https://github.com/JDAI-CV/dabnn)![GitHub stars](https://img.shields.io/github/stars/JDAI-CV/dabnn.svg?style=flat&label=Star)
- dabnn is an accelerated binary neural networks inference framework for mobile platform
- [flame](https://github.com/flame)/**[how-to-optimize-gemm](https://github.com/flame/how-to-optimize-gemm)** 

  - A step-by-step gemm optimization tutorial



# Attractive blogs
## 量化
- :star: [二值化神经网络(BNN)综述 - Ironboy的文章 - 知乎](https://zhuanlan.zhihu.com/p/270184068)
- [神经网络模型量化方法简介](http://chenrudan.github.io/blog/2018/10/02/networkquantization.html)
- [模型压缩算法汇总](https://g.yuque.com/u1267820/ynt2l2/wrbzgy)


- [Making Neural Nets Work With Low Precision](https://sahnimanas.github.io/post/quantization-in-tflite/)


- [Compression and Acceleration of High-dimensional Neural Networks](https://software.intel.com/content/www/us/en/develop/articles/compression-and-acceleration-of-high-dimensional-neural-networks.html)
- [distiller - 非对称量化和对称量化的理论推导](https://intellabs.github.io/distiller/algo_quantization.html)
- [NVIDIA Deep Learning Performance Documentation](https://docs.nvidia.com/deeplearning/performance/index.html) ——英伟达yyds!
- [闲话模型压缩之量化（Quantization）篇](https://jinzhuojun.blog.csdn.net/article/details/106955059)
- [Anatomy of a High-Speed Convolution](https://sahnimanas.github.io/post/anatomy-of-a-high-performance-convolution/)

## 剪枝

- [论文总结 - 模型剪枝 Model Pruning](https://xmfbit.github.io/2018/10/03/paper-summary-model-pruning/)

- [闲话模型压缩之网络剪枝（Network Pruning）篇](https://blog.csdn.net/jinzhuojun/article/details/100621397)

- https://www.yuque.com/yahei/hey-yahei/opsummary.mxnet)

- https://segmentfault.com/a/1190000020993594)

## BiliBili
###  量化
- 神经网络量化 [BiliBili](https://www.bilibili.com/video/BV1u7411W7zL/?spm_id_from=333.788.recommend_more_video.2) [code](https://github.com/mepeichun/Efficient-Neural-Network-Bilibili)

- [Google Developer Days - 模型优化与量化](https://www.bilibili.com/video/BV1RJ411g7Hr/?spm_id_from=333.788.recommend_more_video.14)

- [ :star: 哈佛大学在读博士董鑫：模型量化—更小更快更强](https://www.bilibili.com/video/BV19J411R7t2/?spm_id_from=333.788.recommend_more_video.21)

