<!DOCTYPE html><html lang="zh" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.2.2" /><meta property="og:title" content="【WIP】推理图优化方法小结" /><meta name="author" content="Zhang Ge" /><meta property="og:locale" content="zh" /><meta name="description" content="在神经网络推理过程中，图优化可以达到降低运算量、减少算子invoke数目与降低缓存开销等效果，提升推理效率。本文对常见的推理图优化方法进行小结，并不断增补中。" /><meta property="og:description" content="在神经网络推理过程中，图优化可以达到降低运算量、减少算子invoke数目与降低缓存开销等效果，提升推理效率。本文对常见的推理图优化方法进行小结，并不断增补中。" /><link rel="canonical" href="https://zhangge6.github.io/posts/%E6%8E%A8%E7%90%86%E5%9B%BE%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%B0%8F%E7%BB%93/" /><meta property="og:url" content="https://zhangge6.github.io/posts/%E6%8E%A8%E7%90%86%E5%9B%BE%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%B0%8F%E7%BB%93/" /><meta property="og:site_name" content="ZhangGe’s Blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-02-13T20:31:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="【WIP】推理图优化方法小结" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@Zhang Ge" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Zhang Ge"},"dateModified":"2023-11-20T23:38:44+08:00","datePublished":"2023-02-13T20:31:00+08:00","description":"在神经网络推理过程中，图优化可以达到降低运算量、减少算子invoke数目与降低缓存开销等效果，提升推理效率。本文对常见的推理图优化方法进行小结，并不断增补中。","headline":"【WIP】推理图优化方法小结","mainEntityOfPage":{"@type":"WebPage","@id":"https://zhangge6.github.io/posts/%E6%8E%A8%E7%90%86%E5%9B%BE%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%B0%8F%E7%BB%93/"},"url":"https://zhangge6.github.io/posts/%E6%8E%A8%E7%90%86%E5%9B%BE%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%B0%8F%E7%BB%93/"}</script><title>【WIP】推理图优化方法小结 | ZhangGe's Blog</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="ZhangGe's Blog"><meta name="application-name" content="ZhangGe's Blog"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get MODE_ATTR() { return "data-mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } static get ID() { return "mode-toggle"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } let self = this; /* always follow the system prefers */ this.sysDarkPrefers.addEventListener("change", () => { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.notify(); }); } /* constructor() */ get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; } get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } setDark() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_ATTR); sessionStorage.removeItem(ModeToggle.MODE_KEY); } /* Notify another plugins that the theme mode has changed */ notify() { window.postMessage({ direction: ModeToggle.ID, message: this.modeStatus }, "*"); } } /* ModeToggle */ const toggle = new ModeToggle(); function flipMode() { if (toggle.hasMode) { if (toggle.isSysDarkPrefer) { if (toggle.isLightMode) { toggle.clearMode(); } else { toggle.setLight(); } } else { if (toggle.isDarkMode) { toggle.clearMode(); } else { toggle.setDark(); } } } else { if (toggle.isSysDarkPrefer) { toggle.setLight(); } else { toggle.setDark(); } } toggle.notify(); } /* flipMode() */ </script><body data-spy="scroll" data-target="#toc" data-topbar-visible="true"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src=" https://cdn.jsdelivr.net/gh/cotes2020/chirpy-images/commons/avatar.jpg " alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">ZhangGe's Blog</a></div><div class="site-subtitle font-italic">Stay hungry, stay foolish.</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tag ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center"> <button class="mode-toggle btn" aria-label="Switch Mode"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/ZhangGe6" aria-label="github" target="_blank" rel="noopener"> <i class="fab fa-github"></i> </a> <a href="https://twitter.com/twitter_username" aria-label="twitter" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['sjtu.zg123','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></div><div id="topbar-wrapper" class="row justify-content-center"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Home </a> </span> <span>【WIP】推理图优化方法小结</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="core-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>【WIP】推理图优化方法小结</h1><div class="post-meta text-muted"><div> By <em> <a href="https://twitter.com/username">ZhangGe</a> </em></div><div class="d-flex"><div> <span> Posted <em class="timeago" data-ts="1676291460" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2023-02-13 </em> </span> <span> Updated <em class="timeago" data-ts="1700494724" data-toggle="tooltip" data-placement="bottom" data-tooltip-df="llll" > 2023-11-20 </em> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1402 words"> <em>7 min</em> read</span></div></div></div><div class="post-content"><p>在神经网络推理过程中，图优化可以达到降低运算量、减少算子invoke数目与降低缓存开销等效果，提升推理效率。本文对常见的推理图优化方法进行小结，并不断增补中。</p><h1 id="符号定义">符号定义</h1><h2 id="卷积全连接层运算"><span class="mr-2">卷积、全连接层运算</span><a href="#卷积全连接层运算" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>设卷积或全连接层$Layer(W, b)$的权重和偏置为\(W\)和\(b\)，输入和输出分别为\(X\)和\(X^{\prime}\)，有</p><p>\(X^{\prime} = X \otimes W + b\) 其中$\otimes$代表卷积或矩阵乘法操作。$X \in \mathbf{R}^{c\times h \times w}, \ \ X^{\prime} \in \mathbf{R}^{c^{\prime} \times h^{\prime} \times w^{\prime}}, \ \ b \in \mathbf{R}^{c^{\prime}}.$</p><p>当$Layer$为卷积层时，$W \in \mathbf{R}^{c^{\prime} \times c \times k \times k}$，当$Layer$为全连接层时，$W \in \mathbf{R}^{c^{\prime} \times c}.$</p><h2 id="bn运算"><span class="mr-2">BN运算</span><a href="#bn运算" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><p>设BN层($\gamma, \beta$)输出和输出分别为\(X\)和\(X^{\prime}\)，有 \(X^{\prime} = \gamma \frac{X - \mu}{\sqrt{\delta^2 + \epsilon}} + \beta\)</p><p>其中${X, X^{\prime}}\in \mathbf{R}^{c\times h \times w}$. $\mu, \sigma, \gamma, \beta$均为逐特征通道的变量，在推理时为固定值，${\mu, \sigma, \gamma, \beta}\in \mathbf{R}^c$.</p><p>关于BN层的更多细节介绍，可参见<a href="https://zhangge6.github.io/posts/%E5%85%B3%E4%BA%8EBatch-Normalization/">关于Batch Normalization</a>。</p><h1 id="网络层融合">网络层融合</h1><h2 id="缩放偏置算子融合"><span class="mr-2">缩放/偏置算子融合</span><a href="#缩放偏置算子融合" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="bn--scale-逐通道"><span class="mr-2">BN + scale (逐通道)</span><a href="#bn--scale-逐通道" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><blockquote><p>对应ncnn中的<code class="language-plaintext highlighter-rouge">NetOptimize::fuse_batchnorm_scale()</code></p></blockquote><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>融合前：X --&gt; [BN] --&gt; X' --&gt; [S] --&gt; Y
融合后：X --&gt; [BN'] --&gt; Y
</pre></table></code></div></div><p>BN层后接一个沿特征通道维度的缩放算子$S\in\mathbf{R}^{c}$，将对应系数逐通道融合进BN层的系数$\gamma, \beta$中即可。</p><h3 id="conv--scale-逐通道"><span class="mr-2">Conv + scale (逐通道)</span><a href="#conv--scale-逐通道" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><blockquote><p>对应ncnn中的<code class="language-plaintext highlighter-rouge">NetOptimize::NetOptimize::fuse_convolution_mul()</code></p></blockquote><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>融合前：X --&gt; [Conv] --&gt; X' --&gt; [S] --&gt; Y
融合后：X --&gt; [Conv'] --&gt; Y
</pre></table></code></div></div><p>卷积层后接一个沿特征通道维度的缩放算子$S\in\mathbf{R}^{c}$，将对应系数逐<u>输出</u>通道（乘积）融合进卷积层的系数$W, b$中即可。</p><h3 id="conv--add-逐通道"><span class="mr-2">Conv + Add (逐通道）</span><a href="#conv--add-逐通道" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><blockquote><p>对应ncnn中的<code class="language-plaintext highlighter-rouge">NetOptimize::NetOptimize::fuse_convolution_add()</code></p></blockquote><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>融合前：X --&gt; [Conv] --&gt; X' --&gt; [Add] --&gt; Y
融合后：X --&gt; [Conv'] --&gt; Y
</pre></table></code></div></div><p>卷积层后接一个沿特征通道维度的偏置算子$A\in\mathbf{R}^{c}$，将对应系数逐<u>输出</u>通道（加和）融合进卷积层的系数$b$中即可。</p><blockquote><p>对应ncnn中的<code class="language-plaintext highlighter-rouge">NetOptimize::fuse_innerproduct_add()</code></p></blockquote><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>融合前：X --&gt; [FC] --&gt; X' --&gt; [Add] --&gt; Y
融合后：X --&gt; [FC'] --&gt; Y
</pre></table></code></div></div><p>FC + Add 和 Conv + Add 原理非常相似。将对应系数逐<u>输出</u>通道（加和）融合进全连接层的系数$b$中即可。</p><h3 id="fc--add-逐通道"><span class="mr-2">FC + Add (逐通道)</span><a href="#fc--add-逐通道" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><p>FC + Act 和 Conv + Act 原理非常相似。此处不再赘述。</p><h2 id="bn层融合"><span class="mr-2">BN层融合</span><a href="#bn层融合" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="conv--bn"><span class="mr-2">Conv + BN</span><a href="#conv--bn" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><blockquote><p>对应ncnn中的<code class="language-plaintext highlighter-rouge">NetOptimize::fuse_convolution_batchnorm()</code></p></blockquote><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>融合前：X --&gt; [Conv] --&gt; X' --&gt; [BN] --&gt; Y
融合后：X --&gt; [Conv'] --&gt; Y
</pre></table></code></div></div><p><a href="https://leimao.github.io/blog/Neural-Network-Batch-Normalization-Fusion/">参考</a></p><blockquote><p>To execute neural network inference, kernels are invoked for neural network layers in order to compute the output tensors given the input tensors. Each kernel call will bring some overhead time….To achieve high throughput and low latency for neural network inference, the rule of thumb is to have fewer large kernel calls instead of many small kernel calls.</p></blockquote><p>卷积输出\(X^{\prime}\)紧接进入BN层，设BN层的输出为\(Y\)，则有</p><p>\(\begin{aligned} Y &amp;= \gamma \frac{X^{\prime} - \mu}{\sqrt{\delta^2 + \epsilon}} + \beta= \gamma \frac{X * W + b - \mu}{\sqrt{\delta^2 + \epsilon}} + \beta \\ &amp;= X * (\frac{\gamma}{\sqrt{\delta^2 + \epsilon}}W) + \beta + \frac{\gamma}{\sqrt{\delta^2 + \epsilon}}(b - \mu) \\ &amp;= X * W^{\prime} + b^{\prime} \end{aligned}\) 即 conv + BN 等效于调用一个权重为\(W^{\prime} = \frac{\gamma}{\sqrt{\delta^2 + \epsilon}}W\)，偏置为\(b^{\prime} = \beta + \frac{\gamma}{\sqrt{\delta^2 + \epsilon}}(b - \mu)\)的新卷积。该步融合减少了kernel的invoke次数，降低了计算量，且省去了原Conv层与BN层之间的缓存开销。</p><h3 id="fc--bn"><span class="mr-2">FC + BN</span><a href="#fc--bn" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><blockquote><p>对应ncnn中的<code class="language-plaintext highlighter-rouge">NetOptimize::fuse_innerproduct_batchnorm()</code></p></blockquote><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>融合前：X --&gt; [FC] --&gt; X' --&gt; [BN] --&gt; Y
融合后：X --&gt; [FC'] --&gt; Y
</pre></table></code></div></div><p>FC + BN 和 Conv + BN 原理非常相似。将对应系数逐<u>输出</u>通道（乘积）融合进全连接层的系数$W, b$中即可。</p><h2 id="激活函数融合"><span class="mr-2">激活函数融合</span><a href="#激活函数融合" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2></h2><h3 id="conv--act-逐元素"><span class="mr-2">Conv + Act (逐元素)</span><a href="#conv--act-逐元素" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><blockquote><p>对应ncnn中的<code class="language-plaintext highlighter-rouge">NetOptimize::NetOptimize::fuse_convolution_activation()</code></p></blockquote><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>融合前：X --&gt; [Conv] --&gt; X' --&gt; [Act] --&gt; Y
融合后：X --&gt; [Conv'] --&gt; X'(inplace Act) -&gt; Y
</pre></table></code></div></div><p>卷积层紧跟逐元素的激活函数，可以直接将卷积层的输出的激活操作原地（inplace）进行，节约一次缓存开销。ncnn目前支持融合的激活函数有<code class="language-plaintext highlighter-rouge">ReLU, Clip, Sigmoid, Mish, HardSwish</code>.</p><p>基于此，Conv + BN + ReLU可先将Conv和BN融合成Conv’，再将ReLU融合inplace操作，从而在省去BN层计算量的同时，减少两次访存。<a href="https://zhuanlan.zhihu.com/p/209029514">参考</a></p><h3 id="fc--act-逐元素"><span class="mr-2">FC + Act (逐元素)</span><a href="#fc--act-逐元素" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><blockquote><p>对应ncnn中的<code class="language-plaintext highlighter-rouge">NetOptimize::fuse_innerproduct_activation()</code></p></blockquote><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>融合前：X --&gt; [FC] --&gt; X' --&gt; [Act] --&gt; Y
融合后：X --&gt; [FC'] --&gt; X'(inplace Act) -&gt; Y
</pre></table></code></div></div><h1 id="冗余算子消除">冗余算子消除</h1><h3 id="消除dropout算子"><span class="mr-2">消除dropout算子</span><a href="#消除dropout算子" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><blockquote><p>对应ncnn中的<code class="language-plaintext highlighter-rouge">NetOptimize::eliminate_dropout()</code></p></blockquote><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>消除前：X --&gt; [dropout] --&gt; Y
消除后：X --&gt; Y
</pre></table></code></div></div><p>dropout算子在推理时不作用，因此可消除。</p><h3 id="消除identity算子"><span class="mr-2">消除identity算子</span><a href="#消除identity算子" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><blockquote><p>对应ncnn中的<code class="language-plaintext highlighter-rouge">NetOptimize::eliminate_noop()</code></p></blockquote><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>消除前：X --&gt; [identity] --&gt; Y
消除后：X --&gt; Y
</pre></table></code></div></div><p>啥不做的算子为啥留着？消除它。</p><h3 id="消除只有一个输出分支的split算子"><span class="mr-2">消除只有一个输出分支的split算子</span><a href="#消除只有一个输出分支的split算子" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><blockquote><p>对应ncnn中的<code class="language-plaintext highlighter-rouge">NetOptimize::eliminate_split()</code></p></blockquote><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>消除前：X --&gt; [split] --&gt; Y (split只有一个输出分支)
消除后：X --&gt; Y
</pre></table></code></div></div><p>当split只有一个输出分支时，该split节点时是冗余的，可以消除。</p><h3 id="消除global-pooling后的flatten算子"><span class="mr-2">消除global pooling后的flatten算子</span><a href="#消除global-pooling后的flatten算子" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3></h3><blockquote><p>对应ncnn中的<code class="language-plaintext highlighter-rouge">NetOptimize::eliminate_flatten_after_global_pooling()</code></p></blockquote><div class="language-plaintext highlighter-rouge"><div class="code-header"> <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>消除前：X --&gt; [global pooling] --&gt; [flatten] --&gt; Y 
消除后：X --&gt; [global pooling] --&gt; Y
</pre></table></code></div></div><p><u>在ncnn中</u>，global pooling后特征的形状是大小为$C$的一维向量，再做flatten操作无实质变化，因此flatten是冗余的，可以消除。</p><h1 id="常量折叠">常量折叠</h1><h1 id="参考">参考</h1><ul><li><a href="https://github.com/Tencent/ncnn/blob/master/tools/ncnnoptimize.cpp">ncnn/tools/optimize</a><li><a href="https://onnxruntime.ai/docs/performance/graph-optimizations.html">Graph Optimizations in ONNX Runtime</a></ul></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/%E5%AE%9E%E8%B7%B5/'>实践</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/" class="post-tag no-text-decoration" >推理加速</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=【WIP】推理图优化方法小结 - ZhangGe&#39;s Blog&amp;url=https://zhangge6.github.io/posts/%E6%8E%A8%E7%90%86%E5%9B%BE%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%B0%8F%E7%BB%93/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=【WIP】推理图优化方法小结 - ZhangGe&#39;s Blog&amp;u=https://zhangge6.github.io/posts/%E6%8E%A8%E7%90%86%E5%9B%BE%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%B0%8F%E7%BB%93/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https://zhangge6.github.io/posts/%E6%8E%A8%E7%90%86%E5%9B%BE%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%B0%8F%E7%BB%93/&amp;text=【WIP】推理图优化方法小结 - ZhangGe&#39;s Blog" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i id="copy-link" class="fa-fw fas fa-link small" data-toggle="tooltip" data-placement="top" title="Copy link" data-title-succeed="Link copied successfully!"> </i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted"><div class="access"><div id="access-lastmod" class="post"><div class="panel-heading">Recently Updated</div><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/Git%E5%AD%A6%E4%B9%A0/">Git学习</a><li><a href="/posts/VS-code%E4%BD%BF%E7%94%A8/">VS code使用</a><li><a href="/posts/Docker%E5%AD%A6%E4%B9%A0/">Docker学习</a><li><a href="/posts/GPU%E9%80%9A%E4%BF%A1%E5%85%83%E8%AF%AD/">GPU通信元语</a><li><a href="/posts/%E5%AF%B9Roofline%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%90%86%E8%A7%A3/">对Roofline模型的理解</a></ul></div><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/ubuntu/">ubuntu</a> <a class="post-tag" href="/tags/github/">github</a> <a class="post-tag" href="/tags/%E8%BD%AC%E8%BD%BD/">转载</a> <a class="post-tag" href="/tags/cheat-sheets/">cheat sheets</a> <a class="post-tag" href="/tags/getting-started/">getting started</a> <a class="post-tag" href="/tags/llm/">LLM</a> <a class="post-tag" href="/tags/pytorch/">pytorch</a> <a class="post-tag" href="/tags/%E5%AE%9E%E8%B7%B5/">实践</a> <a class="post-tag" href="/tags/anaconda/">anaconda</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"><div class="panel-heading pl-3 pt-2 mb-2">Contents</div><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="tail-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/Python-argparse%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95%E5%B0%8F%E7%BB%93/"><div class="card-body"> <em class="timeago small" data-ts="1652182920" > 2022-05-10 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Python argparse使用方法小结</h3><div class="text-muted small"><p> 本页对Python常用的命令行解析模块argparse的常用方法做一个小结，为了清晰和简化，每个例程只涉及一种功能，便于日后参考。 import argparse def parse_args(): parser = argparse.ArgumentParser() parser.add_argument(&#39;name&#39;, help=&#39;test positional a...</p></div></div></a></div><div class="card"> <a href="/posts/Regex%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%AD%A6%E4%B9%A0%E4%B8%8E%E4%BD%BF%E7%94%A8/"><div class="card-body"> <em class="timeago small" data-ts="1660791240" > 2022-08-18 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Regex正则表达式学习与使用</h3><div class="text-muted small"><p> 感觉Regex正则表达式是这样一种东西： 没有需求时去学习它：天啊这一串符号都是什么东西，怎么学啊！ 当有需求用到它并且成功应用时：真是太方便了！真香，要学习！ 动机 最近实习的时候，需要协助处理代码审查系统的告警，其中有大量（约1.6k）的命名风格的问题，需要对原有的变量命名进行批量替换。我用的编辑器是VS Code，它的朴素的字符串替换功能已经不能满足需求了，比如我需要做...</p></div></div></a></div><div class="card"> <a href="/posts/CMake%E5%AD%A6%E4%B9%A0/"><div class="card-body"> <em class="timeago small" data-ts="1666060500" > 2022-10-18 </em><h3 class="pt-0 mt-1 mb-3" data-toc-skip>CMake学习</h3><div class="text-muted small"><p> CMake是一个跨平台、开源的构建工具，在各种大型C/C++项目中被广泛使用。 CMake是一个&quot;generator&quot;，它不会直接编译目标，而是根据CMakeLists.txt生成当前平台编译所需要的文件（如makefile），然后由当前平台编译工具进行编译（如make）。参考 之所以说CMake是跨平台的，是因为CMakeLi...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/Flask%E9%A1%B9%E7%9B%AE%E9%83%A8%E7%BD%B2%E8%AE%B0%E5%BD%95-uwsgi/" class="btn btn-outline-primary" prompt="Older"><p>Flask项目部署记录（uwsgi）</p></a> <a href="/posts/gdb%E5%AD%A6%E4%B9%A0/" class="btn btn-outline-primary" prompt="Newer"><p>gdb学习</p></a></div><script type="text/javascript"> $(function () { const origin = "https://giscus.app"; const iframe = "iframe.giscus-frame"; const lightTheme = "light"; const darkTheme = "dark_dimmed"; let initTheme = lightTheme; if ($("html[data-mode=dark]").length > 0 || ($("html[data-mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches)) { initTheme = darkTheme; } let giscusAttributes = { "src": "https://giscus.app/client.js", "data-repo": "ZhangGe6/ZhangGe6.github.io", "data-repo-id": "R_kgDOHRk9Cg", "data-category": "Announcements", "data-category-id": "DIC_kwDOHRk9Cs4CPOm5", "data-mapping": "pathname", "data-reactions-enabled": "1", "data-emit-metadata": "0", "data-theme": initTheme, "data-input-position": "bottom", "data-lang": "en", "crossorigin": "anonymous", "async": "" }; let giscusScript = document.createElement("script"); Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value)); document.getElementById("tail-wrapper").appendChild(giscusScript); addEventListener("message", (event) => { if (event.source === window && event.data && event.data.direction === ModeToggle.ID) { /* global theme mode changed */ const mode = event.data.message; const theme = (mode === ModeToggle.DARK_MODE ? darkTheme : lightTheme); const message = { setConfig: { theme: theme } }; const giscus = document.querySelector(iframe).contentWindow; giscus.postMessage({ giscus: message }, origin); } }); }); </script></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center text-muted"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://twitter.com/username">ZhangGe</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><div id="access-tags"><div class="panel-heading">Trending Tags</div><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/python/">python</a> <a class="post-tag" href="/tags/ubuntu/">ubuntu</a> <a class="post-tag" href="/tags/github/">github</a> <a class="post-tag" href="/tags/%E8%BD%AC%E8%BD%BD/">转载</a> <a class="post-tag" href="/tags/cheat-sheets/">cheat sheets</a> <a class="post-tag" href="/tags/getting-started/">getting started</a> <a class="post-tag" href="/tags/llm/">LLM</a> <a class="post-tag" href="/tags/pytorch/">pytorch</a> <a class="post-tag" href="/tags/%E5%AE%9E%E8%B7%B5/">实践</a> <a class="post-tag" href="/tags/anaconda/">anaconda</a></div></div></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script> <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/zh.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script> <script defer src="/app.js"></script>
